<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Cloud-Driven Museum Artifact Recognition System</title>
    <link href="/2024/12/04/Cloud-Driven-Museum-Artifact-Recognition-System/"/>
    <url>/2024/12/04/Cloud-Driven-Museum-Artifact-Recognition-System/</url>
    
    <content type="html"><![CDATA[<h1 id="EN-Cloud-Driven-Museum-Artifact-Recognition-System"><a href="#EN-Cloud-Driven-Museum-Artifact-Recognition-System" class="headerlink" title="[EN]Cloud-Driven Museum Artifact Recognition System"></a>[EN]Cloud-Driven Museum Artifact Recognition System</h1><p><strong>Enhancing Artifact Identification with AI and AWS</strong>  </p><h2 id="📖-Project-Background"><a href="#📖-Project-Background" class="headerlink" title="📖 Project Background"></a>📖 Project Background</h2><p>With the development of artificial intelligence and cloud computing technologies, museums have embraced digital transformation to create more engaging visitor experiences. However, traditional artifact recognition systems face several challenges:  </p><ol><li><strong>Hardware Limitations</strong>: Local devices struggle to process large volumes of images, leading to performance issues during peak demand.  </li><li><strong>Real-Time Requirements</strong>: Visitors expect quick access to artifact information, but local computation may cause delays.  </li><li><strong>Reflection and Lighting Issues</strong>: Glass reflections in display cases interfere with image clarity, hindering AI recognition accuracy.  </li></ol><p>To address these issues, we integrated our museum artifact recognition system with <strong>AWS Cloud Platform</strong>, enabling efficient recognition and real-time information delivery.  </p><hr><h2 id="🎯-Project-Goals"><a href="#🎯-Project-Goals" class="headerlink" title="🎯 Project Goals"></a>🎯 Project Goals</h2><ol><li><strong>Utilize Cloud Resources</strong>: Leverage AWS EC2 for powerful computation to meet large-scale artifact recognition needs.  </li><li><strong>Improve Reflection Handling and Recognition</strong>: Process reflection removal and artifact classification via cloud-based AI models.  </li><li><strong>Build a Scalable Architecture</strong>: Design a highly available and scalable system to support museum-wide applications.  </li></ol><hr><h2 id="🌩️-Solution-Architecture"><a href="#🌩️-Solution-Architecture" class="headerlink" title="🌩️ Solution Architecture"></a>🌩️ Solution Architecture</h2><h3 id="1-System-Overview"><a href="#1-System-Overview" class="headerlink" title="1. System Overview"></a>1. System Overview</h3><p>The architecture design is as follows:  </p><ul><li><strong>Two Availability Zones</strong>: Enhance service reliability.  </li><li><strong>Public Subnet</strong>: Includes a Load Balancer to receive and distribute user requests.  </li><li><strong>Private Subnet</strong>: Hosts an EC2 Instances Group for processing reflection removal and artifact recognition tasks.  </li><li><strong>Auto Scaling Group</strong>: Dynamically adjusts the number of EC2 instances based on traffic, ensuring optimal performance and cost efficiency.  </li><li><strong>Internet Gateway</strong>: Enables secure communication between users and the cloud service.  </li></ul><h3 id="2-Cloud-Functionality-Details"><a href="#2-Cloud-Functionality-Details" class="headerlink" title="2. Cloud Functionality Details"></a>2. Cloud Functionality Details</h3><h4 id="AWS-EC2"><a href="#AWS-EC2" class="headerlink" title="AWS EC2"></a><strong>AWS EC2</strong></h4><ul><li><strong>Purpose</strong>: Executes reflection removal and artifact recognition models, delivering high-speed computation.  </li><li><strong>Setup</strong>: Each EC2 instance is pre-installed with a Python environment and TensorFlow Lite to run the Pix2Pix and YOLO models.  </li></ul><h4 id="Load-Balancer"><a href="#Load-Balancer" class="headerlink" title="Load Balancer"></a><strong>Load Balancer</strong></h4><ul><li><strong>Purpose</strong>: Distributes incoming user requests to prevent single points of failure and improve system stability.  </li></ul><h4 id="Auto-Scaling-Group"><a href="#Auto-Scaling-Group" class="headerlink" title="Auto Scaling Group"></a><strong>Auto Scaling Group</strong></h4><ul><li><strong>Purpose</strong>: Automatically scales EC2 instances up or down based on demand, reducing response times during high traffic and cutting costs during low usage.  </li></ul><h3 id="3-Model-Deployment-and-Integration"><a href="#3-Model-Deployment-and-Integration" class="headerlink" title="3. Model Deployment and Integration"></a>3. Model Deployment and Integration</h3><ul><li><strong>Reflection Removal Model (Pix2Pix)</strong>: Removes glass reflections from visitor-uploaded images to enhance clarity.  </li><li><strong>Artifact Recognition Model (YOLO)</strong>: Detects and classifies artifacts in the processed images, returning detailed information.  </li></ul><hr><h2 id="🏆-Expected-Outcomes"><a href="#🏆-Expected-Outcomes" class="headerlink" title="🏆 Expected Outcomes"></a>🏆 Expected Outcomes</h2><h3 id="Performance-Metrics"><a href="#Performance-Metrics" class="headerlink" title="Performance Metrics"></a>Performance Metrics</h3><ul><li><strong>Improved Processing Speed</strong>: Cloud-based processing reduces recognition latency from 5 seconds (local) to 1.5 seconds (cloud).  </li><li><strong>Enhanced Accuracy</strong>: Combined accuracy improves from 92.7% to 94.5% by integrating reflection removal and YOLO detection.  </li></ul><h3 id="Benefits-to-Users"><a href="#Benefits-to-Users" class="headerlink" title="Benefits to Users"></a>Benefits to Users</h3><ol><li><strong>Better Visitor Experience</strong>: Quick image capture and detailed artifact information enhance interactivity.  </li><li><strong>Scalable Application</strong>: Architecture can be replicated for other museums or cultural venues.  </li></ol><hr><h2 id="📲-Demo-Workflow"><a href="#📲-Demo-Workflow" class="headerlink" title="📲 Demo Workflow"></a>📲 Demo Workflow</h2><ol><li>Visitors capture artifact images with their mobile devices and upload them to the server.  </li><li>AWS EC2 processes the images for reflection removal and artifact recognition.  </li><li>The results, including detailed artifact information, are displayed on the user’s device.  </li></ol><hr><h2 id="🎯-Future-Prospects"><a href="#🎯-Future-Prospects" class="headerlink" title="🎯 Future Prospects"></a>🎯 Future Prospects</h2><ol><li><strong>Multi-Language Support</strong>: Expand features to include multi-language artifact descriptions for international visitors.  </li><li><strong>Broader Applications</strong>: Apply the technology to commercial exhibitions, educational institutions, and product showcases.  </li><li><strong>Continuous Model Optimization</strong>: Further enhance recognition speed and accuracy.  </li></ol><hr><h2 id="🤝-Conclusion"><a href="#🤝-Conclusion" class="headerlink" title="🤝 Conclusion"></a>🤝 Conclusion</h2><p>By combining AI and AWS cloud technologies, our museum artifact recognition system overcomes challenges like reflection interference and computational inefficiencies. It delivers faster, more accurate identification, paving the way for smarter cultural heritage solutions. We look forward to collaborating with museums and expanding the system to new sectors to advance digital transformation in cultural preservation.  </p><hr><h1 id="中文-雲端驅動的博物館文物識別系統"><a href="#中文-雲端驅動的博物館文物識別系統" class="headerlink" title="[中文]雲端驅動的博物館文物識別系統"></a>[中文]雲端驅動的博物館文物識別系統</h1><p><strong>結合 AI 與 AWS 提升文物辨識與即時處理能力</strong>  </p><h2 id="📖-專案背景"><a href="#📖-專案背景" class="headerlink" title="📖 專案背景"></a>📖 專案背景</h2><p>隨著人工智慧和雲端技術的發展，博物館的數位化轉型迎來新的機遇。然而，傳統文物辨識系統常面臨以下挑戰：</p><ol><li><strong>硬體資源限制</strong>：本地端設備處理大量圖片時性能受限，無法應對高並發需求。</li><li><strong>即時性需求</strong>：訪客希望快速獲取展品資訊，但本地端運算可能導致延遲。</li><li><strong>反光與光線干擾</strong>：展品在玻璃櫃中拍攝時的反光干擾增加了影像處理的難度。</li></ol><p>為解決上述問題，我們將博物館文物辨識系統與 <strong>AWS 雲端平台</strong> 結合，實現高效的文物辨識與即時資訊提供。</p><hr><h2 id="🎯-專案目標"><a href="#🎯-專案目標" class="headerlink" title="🎯 專案目標"></a>🎯 專案目標</h2><ol><li><strong>結合雲端資源</strong>：利用 AWS EC2 提供高效計算能力，處理大規模文物辨識需求。</li><li><strong>提升反光處理與辨識效率</strong>：通過雲端進行反光消除與文物分類模型推理，提升辨識準確率。</li><li><strong>構建可擴展架構</strong>：設計具高可用性與可擴展性的架構，適應多博物館導覽場景。</li></ol><hr><h2 id="🌩️-解決方案架構"><a href="#🌩️-解決方案架構" class="headerlink" title="🌩️ 解決方案架構"></a>🌩️ 解決方案架構</h2><h3 id="1-系統架構概述"><a href="#1-系統架構概述" class="headerlink" title="1. 系統架構概述"></a>1. 系統架構概述</h3><p>我們的架構設計如下：</p><ul><li><strong>兩個 Availability Zone</strong>：提高服務穩定性。</li><li><strong>Public Subnet</strong>：配置負載均衡器 (Load Balancer)，接收並分發用戶請求。</li><li><strong>Private Subnet</strong>：部署 EC2 實例組 (EC2 Instances Group)，處理反光消除與文物辨識。</li><li><strong>Auto Scaling Group</strong>：根據流量動態調整 EC2 實例數量，確保高性能與成本效益。</li><li><strong>Internet Gateway</strong>：負責用戶與服務之間的安全通信。</li></ul><h3 id="2-雲端功能詳解"><a href="#2-雲端功能詳解" class="headerlink" title="2. 雲端功能詳解"></a>2. 雲端功能詳解</h3><h4 id="AWS-EC2-1"><a href="#AWS-EC2-1" class="headerlink" title="AWS EC2"></a><strong>AWS EC2</strong></h4><ul><li><strong>作用</strong>：作為反光處理與文物辨識模型的執行環境，提供高效運算能力。  </li><li><strong>配置</strong>：每台 EC2 實例預裝 Python 環境與 TensorFlow Lite，用於執行 Pix2Pix 和 YOLO 模型推理。  </li></ul><h4 id="負載均衡-Load-Balancer"><a href="#負載均衡-Load-Balancer" class="headerlink" title="負載均衡 (Load Balancer)"></a><strong>負載均衡 (Load Balancer)</strong></h4><ul><li><strong>作用</strong>：分配用戶請求，避免單點故障，提升系統穩定性。  </li></ul><h4 id="Auto-Scaling-Group-1"><a href="#Auto-Scaling-Group-1" class="headerlink" title="Auto Scaling Group"></a><strong>Auto Scaling Group</strong></h4><ul><li><strong>作用</strong>：根據訪問量動態調整 EC2 實例數量，降低高峰期響應時間，同時節約低流量時的運行成本。  </li></ul><h3 id="3-模型部署與整合"><a href="#3-模型部署與整合" class="headerlink" title="3. 模型部署與整合"></a>3. 模型部署與整合</h3><ul><li>**反光消除模型 (Pix2Pix)**：在 AWS EC2 上處理訪客上傳的圖像，消除玻璃反光干擾。</li><li>**文物識別模型 (YOLO)**：對反光消除後的圖像進行多物件檢測，識別出文物並返回詳細資訊。</li></ul><hr><h2 id="🏆-預期成果"><a href="#🏆-預期成果" class="headerlink" title="🏆 預期成果"></a>🏆 預期成果</h2><ol><li><strong>提升運算效能</strong>：通過雲端計算實現即時處理，辨識速度提高 50%。</li><li><strong>更高的辨識準確率</strong>：結合 Pix2Pix 和 YOLO 模型，整體準確率從 92.7% 提升至 94.5%。</li><li><strong>彈性擴展能力</strong>：支持高峰期同時處理數百名訪客的拍攝需求。</li></ol><hr><h2 id="📊-成果展示"><a href="#📊-成果展示" class="headerlink" title="📊 成果展示"></a>📊 成果展示</h2><h3 id="測試結果"><a href="#測試結果" class="headerlink" title="測試結果"></a><strong>測試結果</strong></h3><ul><li><strong>平均辨識延遲</strong>：從本地端的 5 秒縮短至雲端的 1.5 秒。</li><li><strong>反光處理效果</strong>：在不同光線條件下，反光消除效果穩定，文物細節清晰可見。</li></ul><h3 id="系統效益"><a href="#系統效益" class="headerlink" title="系統效益"></a><strong>系統效益</strong></h3><ol><li><strong>提升用戶體驗</strong>：訪客可以快速拍攝展品並獲取詳細導覽資訊。</li><li><strong>支持多博物館應用</strong>：架構可輕鬆複製並應用於其他博物館或文化場景。</li></ol><hr><h2 id="📲-操作演示"><a href="#📲-操作演示" class="headerlink" title="📲 操作演示"></a>📲 操作演示</h2><ol><li>用戶通過行動設備拍攝展品照片並上傳至伺服器。</li><li>AWS EC2 處理反光消除與文物辨識，返回詳細展品資訊。</li><li>結果顯示在用戶端，提供多語言介紹與互動式內容。</li></ol><hr><h2 id="🎯-未來展望"><a href="#🎯-未來展望" class="headerlink" title="🎯 未來展望"></a>🎯 未來展望</h2><ol><li><strong>多語言支援</strong>：拓展系統功能，支持更多語言的文物導覽。</li><li><strong>更廣泛的應用場景</strong>：將技術應用於商業展覽、教育機構等場景。</li><li><strong>持續優化模型</strong>：進一步提升辨識效率與準確率。</li></ol><hr><h2 id="🤝-結語"><a href="#🤝-結語" class="headerlink" title="🤝 結語"></a>🤝 結語</h2><p>通過結合 AI 與 AWS 雲端技術，我們的博物館文物識別系統成功克服了反光干擾與運算效能挑戰，實現了更高效、更精準的辨識功能。我們期待未來能與更多博物館合作，共同推進文化數位化的進程。</p><hr>]]></content>
    
    
    <categories>
      
      <category>Cloud Computing</category>
      
      <category>Cultural Heritage</category>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Museum Technology</tag>
      
      <tag>Cloud Computing</tag>
      
      <tag>AWS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AI-Assisted Museum Exhibition Classification for Enhanced Museum Experience</title>
    <link href="/2024/10/14/YOLO-Object-Detection-for-Museum-Exhibition-Classification/"/>
    <url>/2024/10/14/YOLO-Object-Detection-for-Museum-Exhibition-Classification/</url>
    
    <content type="html"><![CDATA[<h1 id="EN-AI-Assisted-Museum-Exhibition-Classification-Overcoming-the-Reflection-Challenge"><a href="#EN-AI-Assisted-Museum-Exhibition-Classification-Overcoming-the-Reflection-Challenge" class="headerlink" title="[EN]AI-Assisted Museum Exhibition Classification: Overcoming the Reflection Challenge"></a>[EN]AI-Assisted Museum Exhibition Classification: Overcoming the Reflection Challenge</h1><h2 id="📖-Background"><a href="#📖-Background" class="headerlink" title="📖 Background"></a>📖 Background</h2><p>With advancements in image recognition and AI technologies, museums are eager to develop more intuitive visitor guides. Ideally, visitors could use their mobile devices to snap photos of exhibits, and the system would instantly recognize the artifacts and provide detailed guidance. However, achieving this vision presents multiple challenges:</p><ol><li><strong>Glass Reflections</strong>: Many artifacts are encased in glass display cases, leading to reflections that obscure the objects and impede accurate AI recognition.</li><li><strong>Angles and Positions</strong>: Visitors may struggle to capture complete images due to positioning or angle constraints.</li><li><strong>External Interferences</strong>: Poor lighting or cluttered backgrounds further complicate image recognition.</li></ol><p>To address these challenges, our project developed an AI system that accurately identifies museum exhibits despite these difficulties, especially glass reflections.</p><hr><h2 id="✨-Our-Solution"><a href="#✨-Our-Solution" class="headerlink" title="✨ Our Solution"></a>✨ Our Solution</h2><h3 id="1-Reflection-Removal-Model"><a href="#1-Reflection-Removal-Model" class="headerlink" title="1. Reflection Removal Model"></a>1. Reflection Removal Model</h3><h4 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h4><p>Reflections from display cases are a significant obstacle in museum environments. Existing open-source reflection removal models were insufficient for handling the complex lighting and reflective scenarios found in museum exhibition halls. To overcome this:</p><ul><li>We developed a specialized reflection removal model that adapts to diverse, non-fixed environments.</li><li>We framed the reflection removal task as a <strong>style transformation</strong> and employed the <strong>Pix2pix GAN</strong> model with <strong>Sobel Features</strong> to guide the model’s attention to reflective areas. This approach effectively minimized reflection interference while preserving key artifact details.</li></ul><p><img src="https://i.imgur.com/TWAthUZ.png" alt="Original vs. Sobel Feature"></p><p><img src="https://i.imgur.com/9M682bu.png" alt="Original vs. Reflection Removed"></p><h3 id="2-Artifact-Identification-Model"><a href="#2-Artifact-Identification-Model" class="headerlink" title="2. Artifact Identification Model"></a>2. Artifact Identification Model</h3><p>To identify multiple artifacts within a single photo, we used the <strong>YOLOv8n</strong> model. We manually labeled <strong>2,000 artifact images</strong> and used data augmentation techniques (e.g., flipping, scaling, and brightness adjustments) to enhance model robustness.</p><ul><li>We trained two versions of the model: the original YOLOv8n and a reflection-enhanced version that uses images processed by the reflection removal model.</li></ul><h3 id="3-Combining-Reflection-Removal-and-YOLO-Detection"><a href="#3-Combining-Reflection-Removal-and-YOLO-Detection" class="headerlink" title="3. Combining Reflection Removal and YOLO Detection"></a>3. Combining Reflection Removal and YOLO Detection</h3><p>We developed two artifact identification pathways:</p><ol><li><strong>Original Identification</strong>: Direct YOLOv8n detection on the original images.</li><li><strong>Reflection-Removed Identification</strong>: YOLOv8n detection after removing reflections.</li></ol><p>By comparing the outputs of both versions, we chose the optimal identification result, ensuring accurate artifact recognition across different environments.</p><hr><h2 id="🏆-Results-amp-Achievements"><a href="#🏆-Results-amp-Achievements" class="headerlink" title="🏆 Results &amp; Achievements"></a>🏆 Results &amp; Achievements</h2><h3 id="Data-Outcomes"><a href="#Data-Outcomes" class="headerlink" title="Data Outcomes"></a>Data Outcomes</h3><ul><li><strong>V1 Model (Original YOLO)</strong>: Achieved a classification accuracy of <strong>92.7%</strong>.</li><li><strong>V2 Model (With Reflection Removal)</strong>: Combined accuracy improved to <strong>94.5%</strong>, reducing misclassification and enhancing recognition quality.</li></ul><h3 id="Qualitative-Analysis"><a href="#Qualitative-Analysis" class="headerlink" title="Qualitative Analysis"></a>Qualitative Analysis</h3><ul><li><strong>Focus on Reflections</strong>: The reflection removal model successfully identified reflective areas and minimized interference while preserving exhibit details.</li><li><strong>Detection Improvement</strong>: Combining both reflection removal and YOLO detection reduced misclassifications, especially in environments with high reflections.</li></ul><hr><h2 id="📲-App-Development"><a href="#📲-App-Development" class="headerlink" title="📲 App Development"></a>📲 App Development</h2><p>We deployed the reflection removal and YOLOv8n models in a dual-platform mobile app built using <strong>Android Studio</strong> and <strong>Xcode</strong>. This app allows users to easily capture images of artifacts and get instant, accurate information.</p><p><strong>Core Features</strong></p><ol><li><strong>Camera Functionality</strong>: Users can capture exhibit photos effortlessly.</li><li><strong>Automated Processing</strong>: Photos undergo both reflection removal and artifact identification.</li><li><strong>Interactive Information Display</strong>: Detailed exhibit information is displayed, providing an enhanced visitor experience.</li></ol><h3 id="App-Screenshots"><a href="#App-Screenshots" class="headerlink" title="App Screenshots"></a>App Screenshots</h3><table><thead><tr><th><img src="https://i.imgur.com/CjIMf58.png" alt="Initial App Screen"></th><th><img src="https://i.imgur.com/OXhtYho.png" alt="Camera Opened"></th></tr></thead><tbody><tr><td>Initial app screen when opened</td><td>Camera ready for capturing images</td></tr></tbody></table><table><thead><tr><th><img src="https://i.imgur.com/fQN3SoY.png" alt="Photo Captured"></th><th><img src="https://i.imgur.com/bn5syr6.png" alt="Processed Image Results"></th></tr></thead><tbody><tr><td>Image after capturing</td><td>Results after image processing</td></tr></tbody></table><h3 id="📷-Demo"><a href="#📷-Demo" class="headerlink" title="📷 Demo"></a>📷 Demo</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/dDO6zq5NAl0" frameborder="0" allowfullscreen></iframe><hr><h2 id="🚀-Benefits-amp-Real-World-Application"><a href="#🚀-Benefits-amp-Real-World-Application" class="headerlink" title="🚀 Benefits &amp; Real-World Application"></a>🚀 Benefits &amp; Real-World Application</h2><h3 id="Achievements-amp-Advantages"><a href="#Achievements-amp-Advantages" class="headerlink" title="Achievements &amp; Advantages"></a>Achievements &amp; Advantages</h3><ul><li><strong>Reflection Removal</strong>: Improved artifact recognition in museums with glass display cases.</li><li><strong>YOLO Multi-Object Detection</strong>: Accurate classification even for multiple artifacts in a single image.</li><li><strong>Dual-Platform App</strong>: Available on both iOS and Android, enhancing user accessibility.</li></ul><h3 id="Practical-Application"><a href="#Practical-Application" class="headerlink" title="Practical Application"></a>Practical Application</h3><ol><li><strong>Museum Experience Enhancement</strong>: Visitors can use the app to quickly get information about exhibits, improving interactivity.</li><li><strong>Wider Cultural and Educational Use</strong>: The solution can be expanded to cultural venues such as art galleries and educational institutions.</li></ol><hr><h2 id="🎯-Future-Prospects"><a href="#🎯-Future-Prospects" class="headerlink" title="🎯 Future Prospects"></a>🎯 Future Prospects</h2><ol><li><strong>Model Optimization</strong>: Further optimize reflection removal and YOLO models for better accuracy and faster performance.</li><li><strong>Multi-Language Support</strong>: Expand the app’s UI to support multiple languages for international visitors.</li><li><strong>Broader Applications</strong>: Apply the solution beyond museums, such as product photography, academic research, and commercial exhibits.</li></ol><hr><h2 id="🤝-Summary"><a href="#🤝-Summary" class="headerlink" title="🤝 Summary"></a>🤝 Summary</h2><p>This project has successfully enhanced automated museum exhibit identification, overcoming challenges like glass reflections. We look forward to future collaborations with museums and expanding the solution to other sectors to continue advancing AI in cultural heritage. </p><hr><h1 id="中文-AI輔助博物館展品分類：克服玻璃反光挑戰"><a href="#中文-AI輔助博物館展品分類：克服玻璃反光挑戰" class="headerlink" title="[中文]AI輔助博物館展品分類：克服玻璃反光挑戰"></a>[中文]AI輔助博物館展品分類：克服玻璃反光挑戰</h1><h2 id="📖-背景"><a href="#📖-背景" class="headerlink" title="📖 背景"></a>📖 背景</h2><p>隨著圖像識別技術和AI技術的進步，博物館希望開發更直觀的參觀導覽方式：參觀者可以通過手持行動裝置拍攝展品，系統即時識別展品並提供詳細導覽資訊。然而，要實現這一目標存在多個挑戰：</p><ol><li><strong>玻璃反光</strong>：許多展品放置在玻璃展示櫃中，反光干擾會影響AI對文物的準確識別。</li><li><strong>拍攝角度與位置</strong>：參觀者因位置或角度限制，無法拍攝完整展品影像，影響識別精度。</li><li><strong>外在干擾因素</strong>：光線不足或背景雜亂等因素，增加了拍攝困難度並影響AI辨識效果。</li></ol><p>針對這些挑戰，我們開發了一種AI系統，即便面對上述各種干擾（尤其是玻璃反光），依然能精確識別博物館展品。</p><hr><h2 id="✨-我們的解決方案"><a href="#✨-我們的解決方案" class="headerlink" title="✨ 我們的解決方案"></a>✨ 我們的解決方案</h2><h3 id="1-反光消除模型"><a href="#1-反光消除模型" class="headerlink" title="1. 反光消除模型"></a>1. 反光消除模型</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>展品展示櫃的反光是博物館中一個重大阻礙。現有的開源反光消除模型無法處理博物館展覽廳內的複雜照明和反射場景。為了解決這個問題：</p><ul><li>我們開發了一個針對非固定環境的反光消除模型，能夠適應不同的照明條件和反射情境。</li><li>我們將反光消除任務作為<strong>風格轉換</strong>，採用了基於<strong>Pix2pix GAN</strong>的生成對抗網絡模型，並引入<strong>Sobel Feature</strong>指導模型注意反光區域，有效降低反光干擾，保護展品的關鍵細節。</li></ul><p><img src="https://i.imgur.com/TWAthUZ.png" alt="原始圖與Sobel特徵"></p><p><img src="https://i.imgur.com/9M682bu.png" alt="原始照片與消除反光"></p><h3 id="2-展品識別模型"><a href="#2-展品識別模型" class="headerlink" title="2. 展品識別模型"></a>2. 展品識別模型</h3><p>為了在單張照片中識別出多個展品，我們採用了<strong>YOLOv8n</strong>模型，並對<strong>2000張展品圖像</strong>進行了手動標註，通過數據增強（翻轉、縮放、亮度調整等）來提高模型的穩健性。</p><ul><li>我們訓練了兩個版本的模型：一個是原始YOLOv8n，另一個是利用反光處理後圖像的改進版。</li></ul><h3 id="3-結合反光消除與YOLO檢測"><a href="#3-結合反光消除與YOLO檢測" class="headerlink" title="3. 結合反光消除與YOLO檢測"></a>3. 結合反光消除與YOLO檢測</h3><p>我們開發了兩種展品識別方式：</p><ol><li><strong>原始識別</strong>：直接在原始圖像上應用YOLOv8n檢測。</li><li><strong>反光消除後識別</strong>：經過反光消除模型處理後再進行YOLOv8n檢測。</li></ol><p>通過比較兩種方式的結果，我們選擇了最優的識別結果，確保在不同環境下達到準確的文物識別效果。</p><hr><h2 id="🏆-成果與成就"><a href="#🏆-成果與成就" class="headerlink" title="🏆 成果與成就"></a>🏆 成果與成就</h2><h3 id="數據結果"><a href="#數據結果" class="headerlink" title="數據結果"></a>數據結果</h3><ul><li><strong>V1模型（原始YOLO）</strong>：分類準確率達到**92.7%**。</li><li><strong>V2模型（反光處理後）</strong>：結合準確率提升至**94.5%**，有效減少誤判並提高識別質量。</li></ul><h3 id="質性分析"><a href="#質性分析" class="headerlink" title="質性分析"></a>質性分析</h3><ul><li><strong>專注於反光區域</strong>：反光消除模型成功找出並去除反光干擾，保護展品細節。</li><li><strong>檢測改進</strong>：反光消除與YOLO檢測的結合降低了誤判率，尤其是在反光嚴重的環境中。</li></ul><hr><h2 id="📲-行動應用開發"><a href="#📲-行動應用開發" class="headerlink" title="📲 行動應用開發"></a>📲 行動應用開發</h2><p>我們將反光消除模型與YOLOv8n模型部署在雙平台的行動應用中，利用<strong>Android Studio</strong>和<strong>Xcode</strong>構建，讓用戶能輕鬆拍攝展品照片並獲取詳細資訊。</p><p><strong>核心功能</strong></p><ol><li><strong>相機功能</strong>：用戶可輕鬆拍攝展品照片。</li><li><strong>自動化處理</strong>：照片同時經過反光去除和展品識別處理。</li><li><strong>互動資訊顯示</strong>：提供展品的詳細介紹，提升參觀體驗。</li></ol><h3 id="應用截圖"><a href="#應用截圖" class="headerlink" title="應用截圖"></a>應用截圖</h3><table><thead><tr><th><img src="https://i.imgur.com/CjIMf58.png" alt="初始界面"></th><th><img src="https://i.imgur.com/OXhtYho.png" alt="相機開啟"></th></tr></thead><tbody><tr><td>應用啟動的初始界面</td><td>相機準備拍攝</td></tr></tbody></table><table><thead><tr><th><img src="https://i.imgur.com/fQN3SoY.png" alt="拍攝結果"></th><th><img src="https://i.imgur.com/bn5syr6.png" alt="處理後結果"></th></tr></thead><tbody><tr><td>拍攝後的影像</td><td>圖像處理後的結果</td></tr></tbody></table><h3 id="📷-影片演示"><a href="#📷-影片演示" class="headerlink" title="📷 影片演示"></a>📷 影片演示</h3><iframe width="560" height="315" src="https://www.youtube.com/embed/dDO6zq5NAl0" frameborder="0" allowfullscreen></iframe><hr><h2 id="🚀-實際應用價值"><a href="#🚀-實際應用價值" class="headerlink" title="🚀 實際應用價值"></a>🚀 實際應用價值</h2><h3 id="成就與優勢"><a href="#成就與優勢" class="headerlink" title="成就與優勢"></a>成就與優勢</h3><ul><li><strong>反光消除</strong>：有效改善了博物館中玻璃展示櫃中的文物識別。</li><li><strong>YOLO多目標檢測</strong>：即便在單張影像中包含多個展品，也能準確分類。</li><li><strong>雙平台應用</strong>：同時支援iOS和Android，增強了用戶可達性。</li></ul><h3 id="實際應用"><a href="#實際應用" class="headerlink" title="實際應用"></a>實際應用</h3><ol><li><strong>博物館體驗提升</strong>：參觀者可輕鬆使用應用拍攝並獲取展品資訊，提升互動性。</li><li><strong>文化和教育用途</strong>：此技術可擴展至其他文化場所，如藝術畫廊和教育機構。</li></ol><hr><h2 id="🎯-未來展望"><a href="#🎯-未來展望" class="headerlink" title="🎯 未來展望"></a>🎯 未來展望</h2><ol><li><strong>模型優化</strong>：進一步優化反光消除和YOLO模型，以提高準確率和運行速度。</li><li><strong>多語言支援</strong>：擴展應用界面，支援多種語言，以適應來自世界各地的訪客。</li><li><strong>應用場景拓展</strong>：不僅限於博物館導覽，此方案還可應用於產品拍攝、學術研究和商業展覽等領域。</li></ol><hr><h2 id="🤝-總結"><a href="#🤝-總結" class="headerlink" title="🤝 總結"></a>🤝 總結</h2><p>這個項目成功克服了博物館展品的玻璃反光挑戰，實現了更精確的自動化識別。我們期待未來與更多博物館合作，並將該方案擴展至其他領域，持續推進AI在文化遺產中的應用。</p>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
      <category>Cultural Heritage</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Museum Technology</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>UAV Project</title>
    <link href="/2024/10/04/UAV-project/"/>
    <url>/2024/10/04/UAV-project/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>這個專案展示了使用無人機來進行建築結構檢查的創新方法。傳統的檢查方式不僅昂貴且耗時，還存在風險。通過使用無人機，我們可以捕捉高解析度的影像並收集數據，有效檢查建築結構中的潛在問題。</p><h2 id="核心技術概述"><a href="#核心技術概述" class="headerlink" title="核心技術概述"></a>核心技術概述</h2><ol><li><p><strong>Point Cloud 處理：</strong></p><ul><li>使用 <strong>Point Cloud Library (PCL)</strong> 去噪原始 3D Point Cloud，並應用濾波器去除雜訊，獲得更平滑、真實的表面。</li><li>根據 Point Cloud 的密度，將距離小於某個閾值的點連成線，形成多邊形（Site）。</li><li>去除過近的 Site 邊界，避免無人機進入無法飛行的狹窄區域。</li></ul></li><li><p><strong>Voronoi Diagram 應用：</strong></p><ul><li>利用 Voronoi Diagram 將建築結構劃分為不同區域，每個區域內的點與相應障礙物 (Site) 距離最短。</li><li>這可以讓無人機保持與障礙物的安全距離，進行有效路徑規劃。</li></ul></li><li><p><strong>Delaunay Triangulation：</strong></p><ul><li>由 Voronoi Diagram 生成 Delaunay Triangulation，並利用其垂直特性，使無人機鏡頭保持面向建築物。</li></ul></li></ol><h2 id="檔案和操作流程"><a href="#檔案和操作流程" class="headerlink" title="檔案和操作流程"></a>檔案和操作流程</h2><h3 id="讀取-Point-Cloud-檔案"><a href="#讀取-Point-Cloud-檔案" class="headerlink" title="讀取 Point Cloud 檔案"></a>讀取 Point Cloud 檔案</h3><ul><li><strong>查看點雲</strong>：下載並使用 <strong>CloudCompare</strong> 來查看點雲數據的樣貌。</li><li><strong>連接實驗室 Ubuntu Server</strong>：<ul><li>進入 <code>Desktop/project</code>，所有相關的檔案都在這個資料夾。</li></ul></li></ul><h3 id="程式編寫與執行"><a href="#程式編寫與執行" class="headerlink" title="程式編寫與執行"></a>程式編寫與執行</h3><ol><li><p><strong>寫程式：</strong></p><ul><li>使用以下指令打開編輯器：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">code vicky.cpp<br></code></pre></td></tr></table></figure></li><li>將會自動開啟 <strong>Visual Studio Code</strong> 進行程式編輯。</li></ul></li><li><p><strong>執行程式：</strong></p><ul><li>進入 <code>build</code> 資料夾：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> Desktop/Project/build<br></code></pre></td></tr></table></figure></li><li>生成與編譯：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">cmake ..<br>make<br></code></pre></td></tr></table></figure></li><li>執行程式：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./vicky<br></code></pre></td></tr></table></figure><img src="https://i.imgur.com/ttnQ5tf.png" alt="`.obj` convert to `.pcd`"></li></ul></li></ol><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><h3 id="2024-10-04"><a href="#2024-10-04" class="headerlink" title="2024-10-04"></a>2024-10-04</h3><ul><li><strong>Obj 轉為點雲檔案並過濾非表面數據</strong>：<ul><li><strong>補洞</strong>：處理點雲中的空隙，使表面完整。</li><li><strong>消除內部點（變空心）</strong>：保留物體表面點，將內部點排除，形成空心結構。<blockquote><p>Desktop/point cloud model 直接處理pcd</p></blockquote></li></ul></li></ul><blockquote><p>減少點數的程式碼有了(vicky.cpp)<br>現在只要弄 <a href="https://github.com/valeoai/POCO">POCO: Point Convolution for Surface Reconstruction</a> 找表面的程式碼</p></blockquote><h3 id="2024-10-15"><a href="#2024-10-15" class="headerlink" title="2024-10-15"></a>2024-10-15</h3><p><strong>進度更新：補洞與資料清理</strong></p><h4 id="補洞進行方式："><a href="#補洞進行方式：" class="headerlink" title="補洞進行方式："></a><strong>補洞進行方式</strong>：</h4><ul><li>使用 <strong>RANSAC (Random Sample Consensus)</strong> 偵測並排除點雲中的平面部分。<ul><li>排除牆面上的點，模擬封閉門窗，避免無人機誤入室內。</li><li>剩餘的點雲保留非平面區域（如邊緣與開口）。</li></ul></li></ul><h4 id="操作步驟："><a href="#操作步驟：" class="headerlink" title="操作步驟："></a><strong>操作步驟</strong>：</h4><ol><li>使用 <strong>RANSAC</strong> 移除主要平面點。</li><li>保留非平面區域作為無人機飛行參考。</li><li>接下來將進一步優化補洞，嘗試使用 <code>.las</code> 格式數據進行測試。</li></ol><h3 id="2024-10-22"><a href="#2024-10-22" class="headerlink" title="2024-10-22"></a>2024-10-22</h3><p>本週進度報告主要集中在解決點雲的浮動點與門窗補洞問題。我們完成了以下幾個主要步驟：</p><p><strong>進度更新：補洞與資料清理</strong></p><ol><li><strong>Poisson表面重建</strong>：生成建築物表面的缺失點（如門窗等），成功應用Poisson技術進行補洞。</li><li><strong>距離過濾</strong>：使用KdTree對新生成的點進行距離檢查，過濾掉與原始點雲距離超過10公分的浮動點，確保生成的點與建築物表面相符。</li><li><strong>合併點雲</strong>：最終將經過篩選的Poisson重建點與原始點雲合併，生成完整的點雲，並成功填補了建築物表面的空隙。</li></ol><hr><h3 id="C-程式碼：補洞與過濾"><a href="#C-程式碼：補洞與過濾" class="headerlink" title="C++ 程式碼：補洞與過濾"></a><strong>C++ 程式碼：補洞與過濾</strong></h3><p><strong>Poisson表面重建：</strong>首先使用Poisson表面重建生成缺失區域的點（如門窗等）。這是一種插值技術，會基於現有的點雲生成一個連續的表面。</p><p><strong>距離過濾：</strong>之後，為避免出現不相關的浮動點，使用KdTree來檢查新生成的點與原始點雲的距離。如果生成的點距離原始建築物點雲過遠（超過指定的閾值，例如10公分），則將其過濾掉。</p><p><strong>合併點雲：</strong>最後將經過篩選的Poisson重建點與原始點雲合併，保存完整的點雲，並且補齊建築物表面中的洞。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/io/pcd_io.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/point_types.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/filters/extract_indices.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/segmentation/sac_segmentation.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/surface/poisson.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/features/normal_3d.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/kdtree/kdtree_flann.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;pcl/filters/radius_outlier_removal.h&gt;</span></span><br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>** argv)</span> </span>&#123;<br>    <span class="hljs-comment">// Load input PCD file</span><br>    pcl::PointCloud&lt;pcl::PointXYZ&gt;::<span class="hljs-function">Ptr <span class="hljs-title">cloud</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::PointXYZ&gt;)</span></span>;<br>    <span class="hljs-keyword">if</span> (pcl::io::loadPCDFile&lt;pcl::PointXYZ&gt;(<span class="hljs-string">&quot;/home/wasn/Desktop/Point_Cloud_Model/badminton_court_35000.pcd&quot;</span>, *cloud) == <span class="hljs-number">-1</span>) &#123;<br>        <span class="hljs-built_in">PCL_ERROR</span>(<span class="hljs-string">&quot;Couldn&#x27;t read file badminton_court_35000.pcd \n&quot;</span>);<br>        <span class="hljs-keyword">return</span> (<span class="hljs-number">-1</span>);<br>    &#125;<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Loaded &quot;</span> &lt;&lt; cloud-&gt;points.<span class="hljs-built_in">size</span>() &lt;&lt; <span class="hljs-string">&quot; data points.&quot;</span> &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// Step 1: Segment the large planes (e.g., walls)</span><br>    pcl::SACSegmentation&lt;pcl::PointXYZ&gt; seg;<br>    pcl::<span class="hljs-function">PointIndices::Ptr <span class="hljs-title">inliers</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointIndices)</span></span>;<br>    pcl::<span class="hljs-function">ModelCoefficients::Ptr <span class="hljs-title">coefficients</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::ModelCoefficients)</span></span>;<br>    seg.<span class="hljs-built_in">setOptimizeCoefficients</span>(<span class="hljs-literal">true</span>);<br>    seg.<span class="hljs-built_in">setModelType</span>(pcl::SACMODEL_PLANE);<br>    seg.<span class="hljs-built_in">setMethodType</span>(pcl::SAC_RANSAC);<br>    seg.<span class="hljs-built_in">setDistanceThreshold</span>(<span class="hljs-number">0.01</span>);<br>    seg.<span class="hljs-built_in">setInputCloud</span>(cloud);<br>    seg.<span class="hljs-built_in">segment</span>(*inliers, *coefficients);<br><br>    <span class="hljs-keyword">if</span> (inliers-&gt;indices.<span class="hljs-built_in">empty</span>()) &#123;<br>        <span class="hljs-built_in">PCL_ERROR</span>(<span class="hljs-string">&quot;No planar model found. \n&quot;</span>);<br>        <span class="hljs-keyword">return</span> (<span class="hljs-number">-1</span>);<br>    &#125;<br><br>    <span class="hljs-comment">// Step 2: Extract non-planar regions (e.g., windows and doors)</span><br>    pcl::ExtractIndices&lt;pcl::PointXYZ&gt; extract;<br>    pcl::PointCloud&lt;pcl::PointXYZ&gt;::<span class="hljs-function">Ptr <span class="hljs-title">non_planes</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::PointXYZ&gt;)</span></span>;<br>    extract.<span class="hljs-built_in">setInputCloud</span>(cloud);<br>    extract.<span class="hljs-built_in">setIndices</span>(inliers);<br>    extract.<span class="hljs-built_in">setNegative</span>(<span class="hljs-literal">true</span>); <span class="hljs-comment">// Extract non-planar points</span><br>    extract.<span class="hljs-built_in">filter</span>(*non_planes);<br><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Extracted non-planar points: &quot;</span> &lt;&lt; non_planes-&gt;points.<span class="hljs-built_in">size</span>() &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// Step 3: Generate points using Poisson Surface Reconstruction to fill the gaps</span><br>    pcl::NormalEstimation&lt;pcl::PointXYZ, pcl::Normal&gt; ne;<br>    pcl::PointCloud&lt;pcl::Normal&gt;::<span class="hljs-function">Ptr <span class="hljs-title">normals</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::Normal&gt;)</span></span>;<br>    pcl::search::KdTree&lt;pcl::PointXYZ&gt;::<span class="hljs-function">Ptr <span class="hljs-title">tree</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::search::KdTree&lt;pcl::PointXYZ&gt;)</span></span>;<br>    ne.<span class="hljs-built_in">setInputCloud</span>(non_planes);<br>    ne.<span class="hljs-built_in">setSearchMethod</span>(tree);<br>    ne.<span class="hljs-built_in">setKSearch</span>(<span class="hljs-number">20</span>);<br>    ne.<span class="hljs-built_in">compute</span>(*normals);<br><br>    pcl::PointCloud&lt;pcl::PointNormal&gt;::<span class="hljs-function">Ptr <span class="hljs-title">cloud_with_normals</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::PointNormal&gt;)</span></span>;<br>    pcl::<span class="hljs-built_in">concatenateFields</span>(*non_planes, *normals, *cloud_with_normals);<br><br>    pcl::Poisson&lt;pcl::PointNormal&gt; poisson;<br>    poisson.<span class="hljs-built_in">setDepth</span>(<span class="hljs-number">8</span>); <span class="hljs-comment">// Depth controls the resolution</span><br>    poisson.<span class="hljs-built_in">setInputCloud</span>(cloud_with_normals);<br><br>    pcl::PolygonMesh mesh;<br>    poisson.<span class="hljs-built_in">reconstruct</span>(mesh);<br><br>    <span class="hljs-comment">// Step 4: Convert the mesh back to a point cloud</span><br>    pcl::PointCloud&lt;pcl::PointXYZ&gt;::<span class="hljs-function">Ptr <span class="hljs-title">poisson_cloud</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::PointXYZ&gt;)</span></span>;<br>    pcl::<span class="hljs-built_in">fromPCLPointCloud2</span>(mesh.cloud, *poisson_cloud);  <span class="hljs-comment">// Extract the point cloud from the mesh</span><br><br>    <span class="hljs-comment">// Step 5: Filter out points that are too far from the original point cloud</span><br>    pcl::KdTreeFLANN&lt;pcl::PointXYZ&gt; kdtree;<br>    kdtree.<span class="hljs-built_in">setInputCloud</span>(cloud);<br>    pcl::PointCloud&lt;pcl::PointXYZ&gt;::<span class="hljs-function">Ptr <span class="hljs-title">filtered_poisson</span><span class="hljs-params">(<span class="hljs-keyword">new</span> pcl::PointCloud&lt;pcl::PointXYZ&gt;)</span></span>;<br>    <span class="hljs-keyword">float</span> distance_threshold = <span class="hljs-number">0.1</span>; <span class="hljs-comment">// Set distance threshold to keep points within 10 cm of the original cloud</span><br><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">const</span> <span class="hljs-keyword">auto</span>&amp; point : poisson_cloud-&gt;points) &#123;<br>        std::vector&lt;<span class="hljs-keyword">int</span>&gt; indices;<br>        std::vector&lt;<span class="hljs-keyword">float</span>&gt; distances;<br>        <span class="hljs-keyword">if</span> (kdtree.<span class="hljs-built_in">nearestKSearch</span>(point, <span class="hljs-number">1</span>, indices, distances) &gt; <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">if</span> (distances[<span class="hljs-number">0</span>] &lt; distance_threshold) &#123;<br>                filtered_poisson-&gt;points.<span class="hljs-built_in">push_back</span>(point);<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Filtered Poisson points: &quot;</span> &lt;&lt; filtered_poisson-&gt;points.<span class="hljs-built_in">size</span>() &lt;&lt; std::endl;<br><br>    <span class="hljs-comment">// Step 6: Combine original points with the filtered Poisson points</span><br>    *filtered_poisson += *cloud;  <span class="hljs-comment">// Combine original and filtered points</span><br><br>    <span class="hljs-comment">// Step 7: Save the final combined point cloud</span><br>    pcl::io::<span class="hljs-built_in">savePCDFile</span>(<span class="hljs-string">&quot;../filled_output.pcd&quot;</span>, *filtered_poisson);<br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Saved filled point cloud to ../filled_output.pcd with &quot;</span> &lt;&lt; filtered_poisson-&gt;points.<span class="hljs-built_in">size</span>() &lt;&lt; <span class="hljs-string">&quot; points.&quot;</span> &lt;&lt; std::endl;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="Screened-Poisson-處理前後對比"><a href="#Screened-Poisson-處理前後對比" class="headerlink" title="Screened Poisson 處理前後對比"></a><strong>Screened Poisson 處理前後對比</strong></h3><h4 id="上方視角"><a href="#上方視角" class="headerlink" title="上方視角"></a>上方視角</h4><p><strong>處理前：</strong><br><img src="https://i.imgur.com/SM38vPw.png" alt="處理前"></p><p><strong>處理後：</strong><br><img src="https://i.imgur.com/3i8Fe5P.png" alt="處理後"></p><h4 id="下方視角"><a href="#下方視角" class="headerlink" title="下方視角"></a>下方視角</h4><p><strong>處理前：</strong><br><img src="https://i.imgur.com/STbJvTB.png" alt="處理前"></p><p><strong>處理後：</strong><br><img src="https://i.imgur.com/R7FX0Il.png" alt="處理後"></p><h4 id="側邊視角"><a href="#側邊視角" class="headerlink" title="側邊視角"></a>側邊視角</h4><p><strong>處理前：</strong><br><img src="https://i.imgur.com/C0pI9Xz.png" alt="處理前"></p><p><strong>處理後：</strong><br><img src="https://i.imgur.com/aVsfEX7.png" alt="處理後"></p>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>Algorithm</tag>
      
      <tag>Project</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>10-Day Summer Korea Travel Log</title>
    <link href="/2024/07/23/South-Korea-Travel-Log/"/>
    <url>/2024/07/23/South-Korea-Travel-Log/</url>
    
    <content type="html"><![CDATA[<h1 id="韓國-10-天自由行行程：濟州、江陵、束草、首爾"><a href="#韓國-10-天自由行行程：濟州、江陵、束草、首爾" class="headerlink" title="韓國 10 天自由行行程：濟州、江陵、束草、首爾"></a>韓國 10 天自由行行程：濟州、江陵、束草、首爾</h1><h2 id="📅-行程概覽"><a href="#📅-行程概覽" class="headerlink" title="📅 行程概覽"></a>📅 行程概覽</h2><p>在 2024 年 6 月 24 日至 7 月 3 日之間，踏上韓國 10 天冒險之旅。本行程涵蓋濟州島的美麗景點、沿海城市束草，以及繁忙的首都首爾。從品嚐美食到遊覽迷人的景點，跟隨這篇行程，一同感受難忘的韓國之旅。</p><h2 id="第一天：抵達濟州市區"><a href="#第一天：抵達濟州市區" class="headerlink" title="第一天：抵達濟州市區"></a>第一天：抵達濟州市區</h2><ul><li><strong>航班</strong>：從台北（TPE）出發，於早上 6:05 抵達濟州（CJU）。</li><li><strong>租車</strong>：在濟州機場 Gate 2 租車。</li><li><strong>早餐</strong>：在 <a href="https://naver.me/5Z0vT0W9">宇進解酒湯 (Ujin Haejangguk)</a> 享用溫暖的早餐。</li><li><strong>早晨探索</strong>：參觀 <a href="https://naver.me/IgTNJ9Dq">東門市場 (Dongmun Market)</a>，試圖前往 <a href="https://naver.me/xguFtbDd">Mochiron 達克瓦茲</a>（週一公休）。</li><li><strong>活動</strong>：前往 9.81 Park 參加無重力賽車活動。</li><li><strong>下午咖啡館</strong>：在 <a href="https://naver.me/FwSEaVOw">Tribe Cafe</a> 享用舒芙雷。</li><li><strong>晚餐</strong>：在 <a href="https://naver.me/F423Yhg4">正直的豬烤肉 (Jeongjik’s BBQ)</a> 享用烤肉。</li><li><strong>住宿</strong>：入住農場村度假屋。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C9H5Rbhy7yu/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h2 id="第二天：西歸浦精華"><a href="#第二天：西歸浦精華" class="headerlink" title="第二天：西歸浦精華"></a>第二天：西歸浦精華</h2><ul><li><strong>午餐</strong>：品嘗 <a href="https://naver.me/FlJxW2YF">海鮮辣炒年糕</a>。</li><li><strong>參觀</strong>：參觀本態博物館，並享用冷麵午餐。</li><li><strong>賞花</strong>：下午欣賞繡球花。</li><li><strong>咖啡館</strong>：拜訪時尚的黑色主題 <a href="https://naver.me/5Fh6R4oz">Muroi Cafe</a>。</li><li><strong>夜市</strong>：探索 <a href="https://naver.me/xFprr704">每日偶來市場 (Maeil Olle Market)</a>。</li><li><strong>住宿</strong>：入住 badayeon Pool Villa。</li></ul><h2 id="第三天：東濟州與度假村休閒"><a href="#第三天：東濟州與度假村休閒" class="headerlink" title="第三天：東濟州與度假村休閒"></a>第三天：東濟州與度假村休閒</h2><ul><li><strong>風景駕車</strong>：參觀三達里漁村和秘密森林。</li><li><strong>早午餐</strong>：在 <a href="https://naver.me/FJ6YMyT4">London Bagel Cafe</a> 享用貝果。</li><li><strong>晚餐</strong>：在 <a href="https://naver.me/FJ6YMyT4">Mint Restaurant</a> 預訂靠窗座位，欣賞美麗的夕陽景色。</li><li><strong>住宿</strong>：入住鳳凰島度假村。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C9AA7sWzybs/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h2 id="第四天：水族館與雨天休閒"><a href="#第四天：水族館與雨天休閒" class="headerlink" title="第四天：水族館與雨天休閒"></a>第四天：水族館與雨天休閒</h2><ul><li><strong>早晨</strong>：參觀 <a href="https://naver.me/GDc5XdDe">Aqua Planet Jeju</a>。</li><li><strong>午餐</strong>：在知名的黑豬肉餐廳用餐（<a href="https://naver.me/GiHtYag3">連結</a>）。</li><li><strong>下午</strong>：由於下雨，在飯店休息。</li><li><strong>晚餐</strong>：享用 BHC 炸雞。</li><li><strong>住宿</strong>：入住城山城市酒店。</li></ul><h2 id="第五天：牛島冒險"><a href="#第五天：牛島冒險" class="headerlink" title="第五天：牛島冒險"></a>第五天：牛島冒險</h2><ul><li><strong>早晨渡輪</strong>：搭渡輪前往牛島。</li><li><strong>早餐</strong>：品嘗海鮮鮑魚刀削麵。</li><li><strong>午餐</strong>：享用花生冰淇淋和炸豬排。</li><li><strong>返回濟州市區</strong>：晚餐在熟成到黑豬肉用餐。</li><li><strong>住宿</strong>：入住濟州沙崙酒店。</li></ul><h2 id="第六天：前往江陵與束草"><a href="#第六天：前往江陵與束草" class="headerlink" title="第六天：前往江陵與束草"></a>第六天：前往江陵與束草</h2><ul><li><strong>航班</strong>：從濟州（CJU）飛往金浦（GMP）。</li><li><strong>自駕之旅</strong>：租車前往江陵，途中在江陵豆腐村用餐。</li><li><strong>晚餐</strong>：在束草享用雪蟹盛宴。</li><li><strong>住宿</strong>：入住 Sokcho I Park Suite Hotel。</li></ul><h2 id="第七天：束草一日遊"><a href="#第七天：束草一日遊" class="headerlink" title="第七天：束草一日遊"></a>第七天：束草一日遊</h2><ul><li><strong>早餐</strong>：在 <a href="https://naver.me/">中央水產市場 (Jungang Fish Market)</a> 品嘗各種街頭小吃。</li><li><strong>晚餐</strong>：享用在市場購買的新鮮雪蟹及其他海鮮。</li><li><strong>住宿</strong>：入住 Sokcho I Park Suite Hotel。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C9Pcw3KyzdG/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h2 id="第八天：前往首爾"><a href="#第八天：前往首爾" class="headerlink" title="第八天：前往首爾"></a>第八天：前往首爾</h2><ul><li><strong>早起</strong>：在束草觀看日出。</li><li><strong>開車前往首爾</strong>：抵達後歸還租車。</li><li><strong>午餐</strong>：在明洞餃子用餐。</li><li><strong>下午</strong>：在明洞與江南購物。</li><li><strong>晚餐</strong>：與朋友在 Refine 聚餐。</li><li><strong>住宿</strong>：入住弘大 Amanti Hotel。</li></ul><h2 id="第九天：雨天遊首爾"><a href="#第九天：雨天遊首爾" class="headerlink" title="第九天：雨天遊首爾"></a>第九天：雨天遊首爾</h2><ul><li><strong>早晨</strong>：參觀汝矣島的現代百貨。</li><li><strong>午餐</strong>：品嘗 Five Guys 漢堡。</li><li><strong>購物</strong>：晚上逛 Musinsa 和 Olive Young。</li><li><strong>住宿</strong>：入住弘大 Amanti Hotel。</li></ul><h2 id="第十天：首爾的最後一天"><a href="#第十天：首爾的最後一天" class="headerlink" title="第十天：首爾的最後一天"></a>第十天：首爾的最後一天</h2><ul><li><strong>早晨</strong>：漫步望遠市場。</li><li><strong>購物</strong>：參觀 Homeplus 和弘大周邊店鋪。</li><li><strong>機場出發</strong>：抵達仁川機場準備回程。</li><li><strong>晚餐</strong>：在 Shake Shack 用餐。</li></ul><h2 id="🛫-回程"><a href="#🛫-回程" class="headerlink" title="🛫 回程"></a>🛫 回程</h2><ul><li><strong>航班</strong>：從仁川（ICN）出發，於晚上 10:50 飛往台北（TPE），次日凌晨抵達。</li></ul><h2 id="✨-行程亮點"><a href="#✨-行程亮點" class="headerlink" title="✨ 行程亮點"></a>✨ 行程亮點</h2><ul><li><strong>濟州島</strong>：賞繡球花、Mint Restaurant 夕陽景色、London Bagel Cafe。</li><li><strong>束草</strong>：中央水產市場的雪蟹、海灘日出美景。</li><li><strong>首爾</strong>：明洞購物、Five Guys 漢堡、夜晚逛 Musinsa。</li></ul><h2 id="📝-旅遊小貼士"><a href="#📝-旅遊小貼士" class="headerlink" title="📝 旅遊小貼士"></a>📝 旅遊小貼士</h2><ul><li><strong>交通</strong>：在濟州和江陵租車對於探索景點非常重要。</li><li><strong>住宿</strong>：選擇帶泳池的別墅和海邊飯店能提供極好的休閒體驗。</li><li><strong>美食</strong>：濟州的黑豬肉、束草的雪蟹，以及首爾多樣的街頭美食，讓這次旅行充滿了美味的回憶。</li></ul><p>總體來說，此次韓國之旅融合了放鬆、冒險和文化體驗，探索了三個截然不同的地區，留下了美好的回憶。</p>]]></content>
    
    
    <categories>
      
      <category>Travel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>life</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>18-Day Winter Korea Travel Log</title>
    <link href="/2024/03/04/18-Day-Winter-Korea-Travel-Log/"/>
    <url>/2024/03/04/18-Day-Winter-Korea-Travel-Log/</url>
    
    <content type="html"><![CDATA[<h1 id="韓國-18-天寒假追星及旅行紀錄"><a href="#韓國-18-天寒假追星及旅行紀錄" class="headerlink" title="韓國 18 天寒假追星及旅行紀錄"></a>韓國 18 天寒假追星及旅行紀錄</h1><h2 id="📅-行程概覽"><a href="#📅-行程概覽" class="headerlink" title="📅 行程概覽"></a>📅 行程概覽</h2><p>2024 年 2 月 16 日至 3 月 4 日的韓國冬日之旅。<br>追星、文化探索，以及生活體驗，橫跨濟州島、首爾與全州。</p><h2 id="濟州行程"><a href="#濟州行程" class="headerlink" title="濟州行程"></a>濟州行程</h2><h3 id="2-16-涯月邑與蓮洞購物商圈"><a href="#2-16-涯月邑與蓮洞購物商圈" class="headerlink" title="2/16 - 涯月邑與蓮洞購物商圈"></a>2/16 - 涯月邑與蓮洞購物商圈</h3><ul><li><strong>抵達濟州</strong>，前往涯月邑欣賞美麗海景。</li><li><strong>蓮洞購物商圈</strong>：晚上在購物商圈購物，感受濟州市區的氛圍。</li></ul><h3 id="2-17-七星街與東門市場"><a href="#2-17-七星街與東門市場" class="headerlink" title="2/17 - 七星街與東門市場"></a>2/17 - 七星街與東門市場</h3><ul><li><strong>七星街</strong>：早上前往七星街散步，感受濟州當地生活。</li><li><strong>東門市場</strong>：在東門市場購買當地特色美食。</li></ul><h3 id="2-18-咸德海水浴場與倫敦貝果"><a href="#2-18-咸德海水浴場與倫敦貝果" class="headerlink" title="2/18 - 咸德海水浴場與倫敦貝果"></a>2/18 - 咸德海水浴場與倫敦貝果</h3><ul><li><strong>咸德海水浴場</strong>：參觀濟州著名的咸德海水浴場。</li><li>**倫敦貝果 (London Bagel)**：享用美味的貝果和咖啡。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C4R6Hx_x29D/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h3 id="2-19-鐵軌腳踏車與金寧海水浴場"><a href="#2-19-鐵軌腳踏車與金寧海水浴場" class="headerlink" title="2/19 - 鐵軌腳踏車與金寧海水浴場"></a>2/19 - 鐵軌腳踏車與金寧海水浴場</h3><ul><li><strong>鐵軌腳踏車</strong>：騎鐵軌腳踏車，享受沿途美景。</li><li><strong>金寧海水浴場</strong>：下午在金寧海水浴場遊玩。</li><li><strong>黑豬肉晚餐</strong>：品嚐濟州著名的黑豬肉料理。</li><li><strong>東門市場</strong>：晚上再次逛東門市場。</li></ul><h2 id="首爾行程"><a href="#首爾行程" class="headerlink" title="首爾行程"></a>首爾行程</h2><h3 id="2-20-飛往首爾金浦並休息"><a href="#2-20-飛往首爾金浦並休息" class="headerlink" title="2/20 - 飛往首爾金浦並休息"></a>2/20 - 飛往首爾金浦並休息</h3><ul><li><strong>飛濟州到首爾</strong>：從濟州飛往金浦機場，抵達後稍作休息。</li></ul><h3 id="2-21-江南色彩鑑定與汝矣島百貨"><a href="#2-21-江南色彩鑑定與汝矣島百貨" class="headerlink" title="2/21 - 江南色彩鑑定與汝矣島百貨"></a>2/21 - 江南色彩鑑定與汝矣島百貨</h3><ul><li><strong>江南個人色彩鑑定</strong>：參加色彩鑑定，了解個人適合的色調。</li><li><strong>汝矣島現代百貨</strong>：在百貨公司購物。</li><li><strong>Nudake 新沙</strong>：享用時尚甜點。</li><li><strong>江南中華料理</strong>：品嚐江南的丁輝人同款中華料理。</li></ul><h3 id="2-22-美術館與弘大逛街"><a href="#2-22-美術館與弘大逛街" class="headerlink" title="2/22 - 美術館與弘大逛街"></a>2/22 - 美術館與弘大逛街</h3><ul><li><strong>國立現代美術館</strong>：參觀國立現代美術館，欣賞當代藝術。</li><li><strong>onion 安國</strong>：在知名咖啡廳休憩。</li><li><strong>光化門</strong>：觀看金容仙上班路。</li><li><strong>弘大逛街</strong>：在弘大購物。</li></ul><h3 id="2-23-Kwangya、快閃店與拍拍貼機"><a href="#2-23-Kwangya、快閃店與拍拍貼機" class="headerlink" title="2/23 - Kwangya、快閃店與拍拍貼機"></a>2/23 - Kwangya、快閃店與拍拍貼機</h3><ul><li><strong>Kwangya</strong>：探索 K-Pop 世界的 Kwangya 展示空間。</li><li><strong>Lesserafim 快閃店</strong>：參觀 Lesserafim 的快閃店和咖啡廳。</li><li><strong>明洞</strong>：前往明洞購物。</li><li><strong>建國大學</strong>：在附近的拍拍貼機拍照，並買新褲子。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C4VXM3pyuVm/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h3 id="2-24-2-25-丁輝人老婆行程"><a href="#2-24-2-25-丁輝人老婆行程" class="headerlink" title="2/24 - 2/25 - 丁輝人老婆行程"></a>2/24 - 2/25 - 丁輝人老婆行程</h3><ul><li><strong>連續兩天</strong>：見丁輝人老婆，追星行程滿滿。</li></ul><blockquote class="instagram-media" data-instgrm-captioned data-instgrm-permalink="https://www.instagram.com/p/C4LplzqSMtb/?utm_source=ig_embed&amp;utm_campaign=loading" data-instgrm-version="14"></blockquote><script async src="//www.instagram.com/embed.js"></script><h3 id="2-26-漢江咖啡廳與北村晚餐"><a href="#2-26-漢江咖啡廳與北村晚餐" class="headerlink" title="2/26 - 漢江咖啡廳與北村晚餐"></a>2/26 - 漢江咖啡廳與北村晚餐</h3><ul><li><strong>漢江咖啡廳 TYPE</strong>：在漢江邊的咖啡廳休息。</li><li><strong>弘大逛街</strong>：下午繼續逛弘大。</li><li><strong>北村</strong>：享用丁輝人同款的義大利麵。</li></ul><h3 id="2-27-刺青與音樂劇"><a href="#2-27-刺青與音樂劇" class="headerlink" title="2/27 - 刺青與音樂劇"></a>2/27 - 刺青與音樂劇</h3><ul><li><strong>弘大刺青</strong>：在弘大刺青店紋身。</li><li><strong>光化門</strong>：觀看金容仙的音樂劇。</li></ul><h3 id="2-28-逛街與小酒館"><a href="#2-28-逛街與小酒館" class="headerlink" title="2/28 - 逛街與小酒館"></a>2/28 - 逛街與小酒館</h3><ul><li><strong>漢南洞逛街</strong>：探索漢南洞各種時尚商店。</li><li><strong>麻浦散步</strong>：進行丁輝人同款的散步路線。</li><li><strong>乙支路小酒館</strong>：在乙支路的丁輝人同款小酒館喝上一杯。</li></ul><h2 id="全州行程"><a href="#全州行程" class="headerlink" title="全州行程"></a>全州行程</h2><h3 id="2-29-咖啡廳與市場"><a href="#2-29-咖啡廳與市場" class="headerlink" title="2/29 - 咖啡廳與市場"></a>2/29 - 咖啡廳與市場</h3><ul><li><strong>丁輝人同款咖啡廳</strong>：品嚐當地咖啡。</li><li><strong>南部市場</strong>：在南部市場享用血腸湯，並參加硬幣 KTV。</li></ul><h3 id="3-1-做戒指與韓屋村"><a href="#3-1-做戒指與韓屋村" class="headerlink" title="3/1 - 做戒指與韓屋村"></a>3/1 - 做戒指與韓屋村</h3><ul><li><strong>做戒指</strong>：在竹馬同款的地方手作戒指。</li><li><strong>全州韓屋村</strong>：在韓屋村探索並享用各式小吃。</li></ul><h2 id="首爾行程（二回）"><a href="#首爾行程（二回）" class="headerlink" title="首爾行程（二回）"></a>首爾行程（二回）</h2><h3 id="3-2-演唱會之日"><a href="#3-2-演唱會之日" class="headerlink" title="3/2 - 演唱會之日"></a>3/2 - 演唱會之日</h3><ul><li><strong>RBW 咖啡廳</strong>：拜訪 K-Pop 經紀公司 RBW 的咖啡廳。</li><li><strong>蠶室 Ginger Bear 咖啡廳</strong>：品嚐網紅咖啡。</li><li><strong>IU 演唱會</strong>：參加 IU 的演唱會，感受歌迷的熱情。</li></ul><h3 id="3-3-解放村與纛島漢江公園"><a href="#3-3-解放村與纛島漢江公園" class="headerlink" title="3/3 - 解放村與纛島漢江公園"></a>3/3 - 解放村與纛島漢江公園</h3><ul><li><strong>解放村</strong>：探索首爾的解放村。</li><li><strong>首爾林</strong>：漫步首爾林。</li><li><strong>聖水逛街</strong>：在聖水購物。</li><li><strong>纛島漢江公園</strong>：欣賞漢江夕陽美景。</li></ul><h3 id="3-4-回台灣"><a href="#3-4-回台灣" class="headerlink" title="3/4 - 回台灣"></a>3/4 - 回台灣</h3><ul><li><strong>回程</strong>：從金浦機場飛回台灣。</li><li><strong>購物</strong>：在機場附近的樂天百貨和超市最後購物。</li></ul><h2 id="✨-行程亮點"><a href="#✨-行程亮點" class="headerlink" title="✨ 行程亮點"></a>✨ 行程亮點</h2><ul><li><strong>追星經歷</strong>：與丁輝人和 IU 的接觸是此次行程的亮點之一。</li><li><strong>生活體驗</strong>：從漢江邊的咖啡廳到乙支路的小酒館，充分體驗了首爾的生活方式。</li><li><strong>文化探索</strong>：參觀國立現代美術館和全州韓屋村，增強了對韓國文化的理解。</li></ul><p>總體來說，此次韓國 18 天之旅集結了追星、文化、休閒與探索，是一次充滿回憶與驚喜的冬日冒險。</p>]]></content>
    
    
    <categories>
      
      <category>Travel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>life</tag>
      
      <tag>K-Pop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Italy Travel Log</title>
    <link href="/2023/08/08/italy-travel/"/>
    <url>/2023/08/08/italy-travel/</url>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><p>Thanks to my mom and dad for spending money on me.<br>Not many pareants could be so generous about travelling abroad or buying fancy bags for their children.<br><img src="https://i.imgur.com/NwyOHA1.jpg" alt="family"><br><strong><center>Really appreciate it</center></strong></p><h2 id="Date"><a href="#Date" class="headerlink" title="Date"></a>Date</h2><p>From 2023-7-27 to 2023-08-08<br>We didn’t plan on our own since it was our first time heading to Europe, which we didn’t know a lot about there. Hence, we just went there with travel group. </p><h2 id="Day-1"><a href="#Day-1" class="headerlink" title="Day 1"></a>Day 1</h2><h3 id="Before-the-airplane"><a href="#Before-the-airplane" class="headerlink" title="Before the airplane"></a>Before the airplane</h3><p>We were afraid that we couldn’t shabu shabu for awhile, so we went to 海底撈 first.<br><img src="https://i.imgur.com/p5Fhk9C.jpg" alt="hoptpot"></p><h3 id="from-TPE-airport-to-Rome"><a href="#from-TPE-airport-to-Rome" class="headerlink" title="from TPE airport to Rome"></a>from TPE airport to Rome</h3><p>It took us about 14 hours to get there.<br>I ate a lot on the airplane because my dad was full that he left a bit of food and gave them to me. As a fat ass, that was a piece of cake for me to eat them all.<br><img src="https://i.imgur.com/1ONz3gJ.jpg" alt="airplane"></p><h2 id="Day-2"><a href="#Day-2" class="headerlink" title="Day 2"></a>Day 2</h2><h3 id="ROME"><a href="#ROME" class="headerlink" title="ROME"></a>ROME</h3><p>萬神殿<br><img src="https://i.imgur.com/1Vuz4X3.jpg" alt="萬神殿"></p><p>金杯咖啡<br><img src="https://i.imgur.com/5RaQdZf.jpg" alt="coffee"></p><p>許願池<br><img src="https://i.imgur.com/Bf9kIKi.jpg" alt="gelato"></p><p>梵蒂岡<br><img src="https://i.imgur.com/go1O5U1.jpg" alt="pivs"><br><img src="https://i.imgur.com/MRiBrXG.jpg" alt="church"></p><h2 id="Day-3"><a href="#Day-3" class="headerlink" title="Day 3"></a>Day 3</h2><h3 id="PUMPEI"><a href="#PUMPEI" class="headerlink" title="PUMPEI"></a>PUMPEI</h3><p><img src="https://i.imgur.com/rA0hmod.jpg" alt="pumpei"></p>]]></content>
    
    
    <categories>
      
      <category>Travel</category>
      
    </categories>
    
    
    <tags>
      
      <tag>life</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AIGO 人工智慧概論課程</title>
    <link href="/2022/05/30/AIGO%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E6%A6%82%E8%AB%96%E8%AA%B2%E7%A8%8B/"/>
    <url>/2022/05/30/AIGO%E4%BA%BA%E5%B7%A5%E6%99%BA%E6%85%A7%E6%A6%82%E8%AB%96%E8%AA%B2%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="什麼是人工智慧？"><a href="#什麼是人工智慧？" class="headerlink" title="什麼是人工智慧？"></a>什麼是人工智慧？</h2><h3 id="了解人工智慧"><a href="#了解人工智慧" class="headerlink" title="了解人工智慧"></a>了解人工智慧</h3><ul><li>2000~2010 互聯網解放<strong>時間</strong>的限制</li><li>2010~2020 智慧手機解放<strong>空間</strong>的限制</li><li>2015~2025 物聯網解放<strong>溝通</strong>的限制</li><li>2020~2030 人工智慧解放<strong>思考邏輯</strong>的限制</li></ul><h3 id="人工智慧發展趨勢"><a href="#人工智慧發展趨勢" class="headerlink" title="人工智慧發展趨勢"></a>人工智慧發展趨勢</h3><ul><li>1950~1965 萌芽期（符號邏輯）：將人的思維放入電腦</li><li>1980~1990 發展期（專家系統）：將人的領域經驗放入電腦</li><li>2010~now 成長期（機器邏輯）：將人的所見所聞放入電腦</li></ul><h3 id="人工智慧的種類"><a href="#人工智慧的種類" class="headerlink" title="人工智慧的種類"></a>人工智慧的種類</h3><h4 id="弱人工智慧（Weak-AI）"><a href="#弱人工智慧（Weak-AI）" class="headerlink" title="弱人工智慧（Weak AI）"></a>弱人工智慧（Weak AI）</h4><ol><li>只能模仿人類處理特定問題的模式</li><li>不能深度進行思考或推理的人工智慧</li><li>不具意識、不理解動作本身意義</li></ol><h4 id="強人工智慧（Strong-AI）或通用人工智慧（General-AI）"><a href="#強人工智慧（Strong-AI）或通用人工智慧（General-AI）" class="headerlink" title="強人工智慧（Strong AI）或通用人工智慧（General AI）"></a>強人工智慧（Strong AI）或通用人工智慧（General AI）</h4><ol><li>具備與人類同等智慧或超越人類的AI</li><li>擁有自我意識，譨夠像人類大腦一樣思考推理</li><li>目前尚未出現</li></ol><h3 id="AI與傳統學習相異處"><a href="#AI與傳統學習相異處" class="headerlink" title="AI與傳統學習相異處"></a>AI與傳統學習相異處</h3><h4 id="傳統學習"><a href="#傳統學習" class="headerlink" title="傳統學習"></a>傳統學習</h4>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>AIGO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS50 Week 0</title>
    <link href="/2022/05/01/CS50-Week-0/"/>
    <url>/2022/05/01/CS50-Week-0/</url>
    
    <content type="html"><![CDATA[<h2 id="What-is-computer-science"><a href="#What-is-computer-science" class="headerlink" title="What is computer science?"></a>What is computer science?</h2><ul><li><p>Computer science is fundamentally problem solving, but we’ll need to be precise and methodical.</p></li><li><p>We can think of <strong>problem solving</strong> as the process of taking some input (a problem we want to solve) and generate some output (the solution to our problem).<br><img src="https://cs50.harvard.edu/x/2022/notes/0/input_output.png" alt="io"></p></li></ul><h2 id="Representing-numbers"><a href="#Representing-numbers" class="headerlink" title="Representing numbers"></a>Representing numbers</h2><ul><li><p><strong>Decimal system</strong>: 10 digits, 0 through 9 </p></li><li><p><strong>Binary system</strong>: two digits, 0 and 1 (computer using)</p><ul><li>Each binary digit is also called a <strong>bit</strong>.</li><li>In binary, with just two digits, we have powers of two for each place value:<br><img src="https://i.imgur.com/4sM0oBa.png" alt="binaryvalue"></li><li>Most computers use 8 bits at a time</li><li>8 bits = 1 byte</li></ul></li></ul><h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><ul><li><p>The standard mapping, <font color=#800000><strong>ASCII</strong></font><br><img src="https://i.imgur.com/8stRezf.png" alt="ASCII"></p></li><li><p><font color=#800000><strong>Unicode</strong></font>: uses more bits than ASCII to accommodate characters, such as letters with accent marks and symbols in other languages.</p></li><li><p><font color=#800000><strong>emoji</strong></font>: based on the Unicode standard</p></li><li><p>different companies that create software for their devices will have slightly different images that represent each emoji, since only the descriptions have been standardized.</p><ul><li>For example, the “face with medical mask” <mark>11110000 10011111 10011000 10110111</mark><br><img src="https://cs50.harvard.edu/x/2022/notes/0/medical_mask.png" alt="Left is Android and right is iOS"></li></ul></li></ul><h2 id="Images-video-sounds"><a href="#Images-video-sounds" class="headerlink" title="Images, video, sounds"></a>Images, video, sounds</h2><p class="note note-primary">We just came up with some convention for representing.</p><ul><li><p><strong>Color</strong>: RGB( common system that we are using)</p></li><li><p><strong>Image</strong>: made up of many thousands or millions of <strong>pixels</strong>( The dots, or squares, on our screens)</p><blockquote><p>three bytes to represent the color for each pixel</p></blockquote></li><li><p><strong>Video</strong>:sequences of many images, changing multiple times a second to give us the appearance of motion, as a <font color=#800000><strong>flipbook</strong></font> might.</p></li><li><p><strong>Music</strong>: represented by <font color=#800000><strong>MIDI</strong></font> format.</p></li></ul><h2 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h2><ul><li>The black box that transforms inputs to outputs contains algorithms, step-by-step instructions for solving problems:<br><img src="https://cs50.harvard.edu/x/2022/notes/0/algorithms.png?70" alt="algorithm"></li></ul><h2 id="Pseudocode"><a href="#Pseudocode" class="headerlink" title="Pseudocode"></a>Pseudocode</h2><ul><li><p><strong>Pseudocode</strong>: a representation of our algorithm in precise English (or some other human language):</p><div class="note note-light">            <ol><li>Pick up phone book</li><li>Open to middle of phone book</li><li>Look at page</li><li>If person is on page</li><li>   Call person</li><li>Else if person is earlier in book</li><li>   Open to middle of left half of book</li><li>   Go back to line 3</li><li>Else if person is later in book</li><li>  Open to middle of right half of book</li><li>  Go back to line 3</li><li>Else</li><li>  Quit</li></ol>          </div></li><li><p><strong>Functions</strong>: actions or verbs that solve smaller problems</p><div class="note note-light">            <ol><li><strong>Pick up</strong> phone book</li><li><strong>Open to</strong> middle of phone book</li><li><strong>Look at</strong> page</li><li>If person is on page</li><li>   <strong>Call</strong> person</li><li>Else if person is earlier in book</li><li>   <strong>Open to</strong> middle of left half of book</li><li>   Go back to line 3</li><li>Else if person is later in book</li><li>  <strong>Open to</strong> middle of right half of book</li><li>  Go back to line 3</li><li><strong>Else</strong></li><li>  Quit</li></ol>          </div></li></ul><ul><li><p><strong>Conditionals</strong>: branches that lead to different paths, like forks in the road.</p><div class="note note-light">            <ol><li>Pick up phone book</li><li>Open to middle of phone book</li><li>Look at page</li><li><strong>If</strong> person is on page</li><li>   Call person</li><li><strong>Else if</strong> person is earlier in book</li><li>   Open to middle of left half of book</li><li>   Go back to line 3</li><li><strong>Else if</strong> person is later in book</li><li>  Open to middle of right half of book</li><li>  Go back to line 3</li><li><strong>Else</strong></li><li>  Quit</li></ol>          </div></li><li><p><strong>Boolean expressions</strong>:the questions that decide where we go, which eventually result in answers of yes or no, or true or false.</p><div class="note note-light">            <ol><li>Pick up phone book</li><li>Open to middle of phone book</li><li>Look at page</li><li>If <strong>person is on page</strong></li><li>   Call person</li><li>Else if <strong>person is earlier in book</strong></li><li>   Open to middle of left half of book</li><li>   Go back to line 3</li><li>Else if <strong>person is later in book</strong></li><li>  Open to middle of right half of book</li><li>  Go back to line 3</li><li>Else</li><li>  Quit</li></ol>          </div></li><li><p><strong>Loops</strong>:words that create cycles, where we can repeat parts of our program.</p><div class="note note-light">            <ol><li>Pick up phone book</li><li>Open to middle of phone book</li><li>Look at page</li><li>If person is on page</li><li>   Call person</li><li>Else if person is earlier in book</li><li>   Open to middle of left half of book</li><li>   <strong>Go back to line 3</strong></li><li>Else if person is later in book</li><li>  Open to middle of right half of book</li><li>  <strong>Go back to line 3</strong></li><li>Else</li><li>  Quit</li></ol>          </div></li></ul><h2 id="Scratch"><a href="#Scratch" class="headerlink" title="Scratch"></a>Scratch</h2><ul><li><strong>Scratch</strong>: graphical programming language, where we’ll drag and drop blocks that contain instructions.</li></ul><p><img src="https://cs50.harvard.edu/x/2022/notes/0/scratch.png" alt="scratch"></p><ul><li>Scratch categorizes its pieces, each of which might be a function, conditional, or more:<ul><li><strong>Motion</strong>: move</li><li><strong>Events</strong>: blocks will activate when something happens</li><li><strong>Control</strong>: only do something if the Boolean expression inside is true</li><li><strong>Sensing</strong>: includes those Boolean expressions, or questions like whether the sprite is touching the mouse pointer</li><li><strong>Operators</strong>: contains blocks that let us do math or pick random numbers, or combine multiple Boolean expressions</li><li><strong>Variables</strong>: will let us store values like words or numbers, and save them with names like x, y, or other full words to describe them.</li><li><strong>My Blocks</strong>: combine multiple blocks ourselves into a new puzzle piece, or function</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS50</tag>
      
      <tag>Scratch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AIGO – 高中職生 AI 扎根系列活動</title>
    <link href="/2022/03/20/AIGO-1/"/>
    <url>/2022/03/20/AIGO-1/</url>
    
    <content type="html"><![CDATA[<h2 id="學習動機"><a href="#學習動機" class="headerlink" title="學習動機"></a>學習動機</h2><p>除了高二時接觸過的競程之外，也對電資其他領域倍感好奇，高二下時同學介紹此活動給我，看到這系列的活動能讓我完整了解 AI，於是我決定報名參加此活動，藉以探索自己是否對 AI 有興趣。</p><h2 id="活動內容"><a href="#活動內容" class="headerlink" title="活動內容"></a>活動內容</h2><h3 id="第一階段"><a href="#第一階段" class="headerlink" title="第一階段"></a>第一階段</h3><h2 id="方式"><a href="#方式" class="headerlink" title="方式:"></a>方式:</h2><ol><li><p>第一階段—線上課程：共計 31 小時的線上課程，要自己上網看影片或是講義學習，而每堂課結束都會有測驗已作為該堂課的成績。<br><img src="https://i.imgur.com/KUQZK7u.jpg" alt="firstcourse"></p></li><li><p>第二階段—實作體驗營：先提供 3 小時 45 分鐘的影片給我們學習，之後進行線上分組，分組後的第四天進行線上直播提案。<br><img src="https://i.imgur.com/vUCox0q.jpg" alt="secondcourse"></p></li><li><p>第三階段—成果展暨企業分享：主辦以 Gather Town 打造虛擬會場，讓我們用 2D 虛擬人物在線上進行互動。<br><img src="https://media2.giphy.com/media/IbIiDr8dGrcLCScpQi/giphy.gif?cid=790b76115c9eb9b94574b18f0583b6013733d367aa53761c&rid=giphy.gif&ct=g" alt="gather"></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>AIGO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++初學紀錄</title>
    <link href="/2021/06/16/C-%E5%88%9D%E5%AD%B8%E7%B4%80%E9%8C%84/"/>
    <url>/2021/06/16/C-%E5%88%9D%E5%AD%B8%E7%B4%80%E9%8C%84/</url>
    
    <content type="html"><![CDATA[<h3 id="學習動機"><a href="#學習動機" class="headerlink" title="學習動機"></a>學習動機</h3><p>高一升高二暑假參加「SITCON 學生計算機年會」後對資訊領域產生興趣，詢問同學和爬文後決定 從應用最廣泛的 C++語言入門，也因其能<strong>奠定扎實的電腦知識和程式基礎</strong>，因而選擇了 C++。</p><h2 id="學習內容和方式"><a href="#學習內容和方式" class="headerlink" title="學習內容和方式:"></a>學習內容和方式:</h2><h3 id="內容"><a href="#內容" class="headerlink" title="內容"></a>內容</h3><p>照 SCIST 教材編排，學習 C++基礎語法:變數、資料型別、運算子、選擇結構、迴圈 結構、陣列、二維陣列、搜尋與排序。</p><h3 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h3><p>自主學習時間觀看 SCIST 釋出的教學影片，搭配教材和提供的例題鞏固所學的語法， 並在課餘時間到 Zero Judge 練習更多題目。</p><h3 id="計畫書-amp-解題紀錄"><a href="#計畫書-amp-解題紀錄" class="headerlink" title="計畫書&amp;解題紀錄"></a>計畫書&amp;解題紀錄</h3><ol><li><a href="https://reurl.cc/WX30OD">計畫書</a></li><li><a href="https://reurl.cc/6DaKeO">解題紀錄</a></li></ol><h2 id="學習經歷與突破"><a href="#學習經歷與突破" class="headerlink" title="學習經歷與突破:"></a>學習經歷與突破:</h2><h3 id="109-學年度上學期-學習語法"><a href="#109-學年度上學期-學習語法" class="headerlink" title="109 學年度上學期(學習語法)"></a>109 學年度上學期(學習語法)</h3><p><code>數學能力:部分題目要用到較難的數學觀念或公式，但我還沒學過。 </code></p><ul><li>舉例:學到陣列時常常需要矩陣的觀念，但高二上還沒學到。</li><li> 突破:當時空下的題目，等到高二下學到時回頭解就有解出來。</li></ul><p><code>除錯能力:如果程式碼出錯，我很難察覺自己的錯誤，因此自學時常常會因為這 樣而洩氣。</code></p><ul><li>舉例 1:迴圈的題目，我比較熟悉用 for，所以遇到要用 while 的題目邏輯就 會打結。</li><li> 突破:多次詢問同學，熟悉 while 會出現的情況。</li><li>舉例 2:有時答案錯誤但找不出自己是從哪個部分出錯，只能透過別人幫忙<br>debug 才知道。</li><li> 突破:學習在程式的每一個小段落輸出，檢查自己的程式碼是在哪個部<br>分出錯。</li></ul><p><code> 時間管理:自學很考驗自律，彈性學習時間很容易因分心而沒完成計畫進度。</code></p><ul><li>舉例:考前一週或當週的彈性學習時間常常被我拿去讀書。</li><li>突破:因為無法避免考前讀書，我會在考完後另找時間將進度補齊。</li></ul><h3 id="109-學年度下學期-成果檢核"><a href="#109-學年度下學期-成果檢核" class="headerlink" title="109 學年度下學期(成果檢核)"></a>109 學年度下學期(成果檢核)</h3><ol><li><p>2021/01/09 大學程式設計先修檢測 <strong>觀念第2級/實作第2級</strong><br>比起平常每個觀念獨立的題目，APCS的題目是將全部的觀念結合成一題，而當時的我因為沒考過且程式思維訓練不足，導致觀念和實作都只有第2級，但也因此我在考完後學會先在白紙上寫出思考迴路，還有擷取題目關鍵字以找出適 合的解法。</p></li><li><p>2021/01/30 NHDK 四校聯合初學者程式設計實體賽 <strong>團體第4名</strong> <strong>個人第13名</strong> </p></li></ol><ul><li>第一次參加實體賽</li><li>學會比賽時用子題撈分</li><li>發現團體賽的優點(效率更高、自己的盲點組員可以幫忙糾正)<br><img src="https://i.imgur.com/qewDFxC.png" alt="nhdk"></li></ul><ol start="3"><li>2021年奧林匹亞選訓營選拔推廣計畫線上練習賽(TOI)<strong>累積成績830/900分</strong></li></ol><ul><li>心得:2020年10月有參加過一次TOI練習賽，當時對解題的切入還很生疏，又因為要在90分鐘內解出3題感到十分緊張，所以最終只完成一題，經過一 學期的練習，我學會如何檢查自己的程式碼、找出錯誤所在，我認為這項技 巧幫助我許多，讓我在2021年3月、4月、5月三次練習賽能夠獲得300、 230、300的佳績。</li><li>體悟:程式就像學習語言一樣要不斷練習，因為寒假時很少接觸因此我幾乎 把語法忘光了，所以我在這學期常常趁讀書閒暇到Online Judge寫個幾題， 來保持手感。</li><li>困難:因為有時間限制，所以解題時太緊張一直出錯，導致時間流失就壓縮 到姐後面題目的時間。</li><li>轉折:在編譯器一直找不出錯誤，所以我想到之前學過的先將題目脈絡寫在 紙上順過一次，再轉成程式碼就能知道錯誤所在。<br><img src="https://i.imgur.com/OngVsxC.png" alt="toi"></li></ul><ol start="4"><li>校內資訊學科能力競賽 決賽 <strong>第二名</strong> 因爲之前已經有過幾次練習賽的經驗，時間壓力的影響減少不少，也就沒緊張到思緒亂掉，這也讓我再次體悟到程式是需要不斷練習以訓練自身的邏輯思維。</li></ol><h2 id="自我省思"><a href="#自我省思" class="headerlink" title="自我省思"></a>自我省思</h2><h3 id="自我評價"><a href="#自我評價" class="headerlink" title="自我評價"></a>自我評價</h3><p>從零開始到現在能有基本的程式能力，雖然期間也會因爲時間管理不佳拖延進度，或 是因為解不出來而感到挫折想放棄，但整體而言我認為 109 學年度自學程式的努力是成果 可以看見的。</p><h3 id="做得好的部分"><a href="#做得好的部分" class="headerlink" title="做得好的部分:"></a>做得好的部分:</h3><ul><li>觀念不懂的都有詢問同學 or 上網查詢。</li><li>看完影片後，能夠將 SCIST 提供的練習題寫完。</li><li>考試前會複習不熟悉的語法(e.g. 排序和搜尋的函式)</li></ul><h3 id="做得不好的部分"><a href="#做得不好的部分" class="headerlink" title="做得不好的部分:"></a>做得不好的部分:</h3><ul><li>考前會把彈性學習時間用來讀書。</li><li>沒有掌握好時間導致進度拖延。</li><li>解不出來時很容易心浮氣躁。</li></ul><h2 id="心得"><a href="#心得" class="headerlink" title="心得:"></a>心得:</h2><p>從高一開始，為了探索自己未來的志向我就不斷在各個領域嘗試，參加不同類型的營 隊和活動，高一升高二的暑假，因緣際會下參加 SITCON 進而對資訊領域產生好奇，因 此，109 學年度我決定利用彈性學習時間自學程式。</p><p>學習的過程中，我學會<strong>自己安排長期的學習計畫</strong>，此外，每當弄清楚一個觀念或解出 一個題目都讓我十分有成就感，這份悸動使我未來還想繼續接觸更多資訊相關的技術。</p><p>綜合上述，我認為學習程式不但讓我<strong>明瞭自己的志向</strong>，也<strong>激發強烈的好奇心</strong>，並從中 找到成就感，之後我也會持續鍛鍊<strong>運算思維</strong>，並思考資訊科技在<strong>生活中的應用</strong>。</p><h2 id="未來規劃"><a href="#未來規劃" class="headerlink" title="未來規劃"></a>未來規劃</h2><ol><li>演算法和資料結構:學完基礎程式語言後，我希望能再精進自己的程式能力，因此想學習難度較高且應用廣泛的演算法和資料結構，所以在 109 學年度下學期我有選修進階程式語言。</li><li>人工智慧:這幾年新興的 AI 科技勢必是未來的趨勢，我認為它的應用讓我們的生活更加方便，因此想要了解其原理，甚至實作出讓自己生活更方便的應用，所以 在 2020 年 5 月到 8 月我參加經濟部工業局主辦的「<strong>AIGO-高中職生 AI 扎根系 列活動</strong>」。</li></ol>]]></content>
    
    
    <categories>
      
      <category>Computer Science</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MUN JOURNEY</title>
    <link href="/2021/06/15/MUN/"/>
    <url>/2021/06/15/MUN/</url>
    
    <content type="html"><![CDATA[<h1 id="Intoduction"><a href="#Intoduction" class="headerlink" title="Intoduction"></a>Intoduction</h1><h3 id="動機"><a href="#動機" class="headerlink" title="動機"></a>動機</h3><p>就讀國中時偶然接觸到模擬聯合國這個活動，但當時礙於英文能力，使我未感興趣。高中再次參加後，發現它對我口條、思維、眼界方面都有很大的幫助，為了更進一步提升自己的能力，我總共參與10場會議，其中2場擔任主席、6場擔任代表、2場擔任工作人員。</p><h1 id="Experience"><a href="#Experience" class="headerlink" title="Experience"></a>Experience</h1><table><thead><tr><th align="center">Date</th><th align="center">Event Name</th><th align="center">Identity</th><th align="center">Photo</th></tr></thead><tbody><tr><td align="center">2017.8.17</td><td align="center">2017 CYCMUN Workshop</td><td align="center">Belgium</td><td align="center"><img src="https://i.imgur.com/BE2nE8J.png" alt="2017CYCMUN"></td></tr><tr><td align="center">2019.8.3</td><td align="center">2019 CYCMUN Workshop</td><td align="center">Indonesia</td><td align="center"><img src="https://i.imgur.com/4mAbhOt.png" alt="2019CYCMUN"></td></tr><tr><td align="center">2019.10.19-2019.10.20</td><td align="center">2019 CJMUN</td><td align="center">Kenya</td><td align="center"><img src="https://i.imgur.com/kmL7l9m.jpg" alt="2019CJMUN"></td></tr><tr><td align="center">2020.2.6-2020.2.7</td><td align="center">2020/CYSHMUN Workshop</td><td align="center">Maldives + Staff</td><td align="center"><img src="https://i.imgur.com/HsBGipL.jpg" alt="CYSHMUN"></td></tr><tr><td align="center">2020.6.6-2020.6.7</td><td align="center">2020 ChiayiMUN</td><td align="center">Italy(Outstanding delegate)</td><td align="center"><img src="https://i.imgur.com/dPSo9tj.jpg?1" alt="ChiayiMUN"></td></tr><tr><td align="center">2020.7.18-2020.7.20</td><td align="center">2020 TransMUN</td><td align="center">Staff</td><td align="center"><img src="https://i.imgur.com/D7GWT7I.png" alt="transmun"></td></tr><tr><td align="center">2020.8.15</td><td align="center">2020 CYCMUN Workshop</td><td align="center">People’s Republic of China</td><td align="center"><img src="https://i.imgur.com/UrPIR6s.jpg" alt="2020CYCMUN"></td></tr><tr><td align="center">2020.12.12-2020.12.13</td><td align="center">2020 CentMUN</td><td align="center">El Salvador</td><td align="center"><img src="https://i.imgur.com/jWIWKwr.png" alt="centmun"></td></tr><tr><td align="center">2021.2.7-2021.2.8</td><td align="center">2021 WTMUN</td><td align="center">Chair</td><td align="center"><img src="https://i.imgur.com/25HMkPm.jpg?1" alt="2021WTMUN"></td></tr><tr><td align="center">2021.5.29-2021.5.30</td><td align="center">2021 Chiayi MUN</td><td align="center">Chair+主辦</td><td align="center">因為疫情而停辦</td></tr></tbody></table><h1 id="Growth"><a href="#Growth" class="headerlink" title="Growth"></a>Growth</h1><h3 id="校內成果發表會"><a href="#校內成果發表會" class="headerlink" title="校內成果發表會"></a>校內成果發表會</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">由學校選出幾位學習歷程統整較優的學生公開發表給其他高三生<br></code></pre></td></tr></table></figure><p><a href="https://reurl.cc/NZryRe">發表會影片</a></p><h3 id="省思"><a href="#省思" class="headerlink" title="省思"></a>省思</h3><p>經過多次參與後，我對模擬聯合國的議規都十分熟練，但我也了解到我們<strong>無法透過模擬聯合國解決全球議題</strong>，因為在模聯場上我們撰寫的解決方案其實一大部分都是國際上已經實行過的，我們只能透過開會理解為何這些議題一直都解決不了，這其中<strong>牽涉到的各種因素</strong>（e.g. 經濟、政治、法規…etc.），都是他繁瑣難解的原因。</p><h3 id="學習收穫"><a href="#學習收穫" class="headerlink" title="學習收穫"></a>學習收穫</h3><ol><li><p>   表達能力：以前我講話總是很含糊不清且沒有重點，在模聯場上發言時我必須在一分鐘內站穩立場<strong>將論點、論據有條理的講清楚</strong>，因此我的表達能力在一次又一次的刺激日益清晰。</p></li><li><p>   統整能力：打一篇有頭有尾的文件一直是很困擾我的任務，剛開始撰寫立場文件、決議文草案我常常毫無頭緒磨練，在請教其他經驗豐富的前輩後，我慢慢掌握其精髓和要點，也統整出自己<strong>撰寫文件的流程</strong>，像是先找出議題主要問題再整理其延伸的細項。</p></li><li><p>   國際視野：在會前準備時，我會因為需要理解國家立場而點進BBC news，並閱覽每一篇跟國家相關的文章來搜集現況，在過程中我就會接收到各式各樣的<strong>時事</strong>，不但讓視野更廣也同時訓練<strong>英文閱讀</strong>。</p></li><li><p>   思考能力：在解決議題的過程中，我需要不斷的思考自己代表國家的利弊，同時也需要與議場上其他國家代表討論，在這樣的刺激下，我能從<strong>多角度切入議題</strong>，在生活上看待事物也會<strong>想的更全面</strong>，不會只是線性的思考。</p></li><li><p>   英文能力：大部分模聯都以英文作為官方語言，一開始我因為害怕開口而無法融入會議，但為了使自己進步，我都會強迫自己參與會議時全程講英文，這樣的刺激補足了「身旁缺乏英文環境」的不足，訓練到平時考卷上無法習得且自身較沒信心的<strong>英文口說</strong>。</p></li><li><p>   社交能力：每場模聯會議都會需要分國家聯盟，如果不主動去找其他國家合作，很容易就會落單，因此在迫使自己與人交流時社交能力就會不斷地被訓練，剛開始我也都是等著別人來找我，但參加多場之後，我能夠放得開的<strong>主動去找人合作</strong>，也在這些社交中<strong>認識外校厲害的代表</strong>。</p></li><li><p>   領導能力：一開始在國家聯盟裡，我也是被領導的其中之一，透過觀察領導者的作為，我在後面幾場模聯也嘗試擔任領導者，從生疏到嫻熟，藉由<strong>擔任大國和主席</strong>，我的<strong>領導能力也駕輕就熟</strong>，能夠越來越順利的<strong>推動、帶領會議的進行</strong>。</p></li></ol><h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>參加模擬聯合國雖然無法對世界有實際作為，但它呈現寫實的世界面貌，帶給我不一樣的視野和思維，也同時訓練到表達、統整、思考、英文、社交、領導諸如此類在任何領域皆十分重要的層面，因為它讓我思想和能力成長很多，我希望能將它推廣給所有人，讓他們也能感受模擬聯合國的影響和魅力。</p><h2 id="代表vs-主席（兩者差異）"><a href="#代表vs-主席（兩者差異）" class="headerlink" title="代表vs.主席（兩者差異）"></a>代表vs.主席（兩者差異）</h2><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">整體而言，代表只要扮演好自己的國家即可，而主席必須比會議中的任何人更熟悉這個議題並掌握好會議的進行，因此，主席通常都是經驗較豐富的人在當。<br></code></pre></td></tr></table></figure><table><thead><tr><th></th><th>擔任代表</th><th>擔任主席</th></tr></thead><tbody><tr><td>會前準備</td><td>撰寫立場文件</td><td>撰寫背景文件、檢查代表的立場文件</td></tr><tr><td>國家資料收集</td><td>自身國家的立場和可能合作國家的概覽。</td><td>所選出的國家都要仔細審核過，並在撰寫背景文件時需要附上此國家在議題中的地位。</td></tr><tr><td>議題了解程度</td><td>1.    自身國家的狀況  2.    國際整體狀況</td><td>1.    國際整體狀況 2.    參與的各國狀況 3.    過往國際作為 4.    可能的解決方案</td></tr><tr><td>會議間</td><td>按照議規與其他國家合作寫出決議文草案</td><td>主持會議、推動會議進行、協助代表、掌握議會狀況</td></tr></tbody></table><h3 id="自身偏好："><a href="#自身偏好：" class="headerlink" title="自身偏好："></a>自身偏好：</h3><p>我認為擔任主席能學到的東西更多，在寫背景文件時，主席需要完整掌握議題的每一個細節，進而濃縮出能讓每位代表看懂的背景文件，而代表只要了解自己國家即可。會議進行時，主席在台上隨時會遇到許多臨時狀況需要立即回應，而代表可以在台下準備好再上台。<br>綜合上述，未來有機會的話，我會以擔任會議主席為目標訓練本身掌握全局的領導能力使自己更上一層樓。</p>]]></content>
    
    
    <categories>
      
      <category>MUN</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MUN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/06/15/hello-world/"/>
    <url>/2021/06/15/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
